% This file was created with JabRef 2.10.
% Encoding: UTF8

@article{silver:alphagozero,
  author   = {D. Silver and et al},
  title    = {Mastering the game of Go without human knowledge},
  journal  = {Nature},
  volume   = {550},
  number   = {7676},
  pages    = {354--359},
  month    = oct,
  year     = {2017},
  keywords = {jrnl, c2017, c201x, c20xx, zz1017, AI, Alpha, AlphaGo
		 Zero, Go, NN, ANN, play, learning, learn,
		 reinforcement},
  abstract = {{"}... Here we introduce an alg. based solely on
		 reinforcement learning, without human data, guidance or
		 domain knowledge beyond game rules. AlphaGo becomes its
		 own teacher: a neural network is trained to predict
		 AlphaGo's own move selections \& also the winner of
		 AlphaGo's games. This NN improves the strength of the
		 tree search, resulting in higher quality move selection
		 \& stronger self-play in the next iteration. Starting
		 tabula rasa, our new program AlphaGo Zero achieved
		 superhuman performance, winning 100--0 against the
		 previously published, champion-defeating AlphaGo.{"} --
		 [https://doi.org/10.1038/nature24270
		 (doi:10.1038/nature24270)]['17].}
}

@book{Russell:AIModern,
  author    = {Stuart Russell and Peter Norvig},
  title     = {Artificial Intelligence: {A} Modern Approach},
  year      = {1995},
  publisher = {Prentice Hall}
}

@inproceedings{Keem:TCAV,
  title     = {Interpretability Beyond Feature Attribution:
		 Quantitative Testing with Concept Activation Vectors
		 (TCAV)},
  author    = {Been Kim and Martin Wattenberg and Justin Gilmer and
		 Carrie J. Cai and James Wexler and Fernanda B.
		 Vi{\'e}gas and Rory Sayres},
  bibdate   = {2019-04-03},
  bibsource = {DBLP,
		 http://dblp.uni-trier.de/db/conf/icml/icml2018.html#KimWGCWVS18},
  publisher = {PMLR},
  year      = {2018},
  volume    = {80},
  booktitle = {ICML},
  editor    = {Jennifer G. Dy and Andreas Krause 0001},
  pages     = {2673--2682},
  series    = {Proceedings of Machine Learning Research},
  url       = {http://proceedings.mlr.press/v80/}
}

@article{LundbergL:shapley,
  title     = {A unified approach to interpreting model predictions},
  author    = {Scott Lundberg and Su-In Lee},
  journal   = {CoRR},
  year      = {2017},
  volume    = {abs/1705.07874},
  bibdate   = {2018-08-13},
  bibsource = {DBLP,
		 http://dblp.uni-trier.de/db/journals/corr/corr1705.html#LundbergL17},
  url       = {http://arxiv.org/abs/1705.07874}
}

@article{Koch:saliency,
  author  = {C. Koch and S. Ullman},
  year    = {1985},
  journal = {Human Neurbiology},
  pages   = {219--227},
  title   = {Shifts in selective visual attention: towards the
		 underlying neural circuitry},
  volume  = {4}
}

@inproceedings{lorentz:heuristic,
  title     = {Programming {B}reakthrough},
  author    = {Richard Lorentz and Therese Horey},
  publisher = {Springer},
  year      = {2013},
  volume    = {8427},
  bibdate   = {2017-05-17},
  bibsource = {DBLP,
		 http://dblp.uni-trier.de/https://doi.org/10.1007/978-3-319-09165-5_5;
		 DBLP,
		 http://dblp.uni-trier.de/db/conf/cg/cg2013.html#LorentzH13},
  booktitle = {Computers and Games},
  editor    = {H. Jaap van den Herik and Hiroyuki Iida and Aske
		 Plaat},
  isbn      = {978-3-319-09164-8},
  pages     = {49--59},
  series    = {Lecture Notes in Computer Science}
}

@article{deepmind:alphafold,
  author   = {A. W. Senior and R. Evans and J. Jumper and et al ...
		 and D. Hassibis},
  title    = {Protein structure prediction using multiple deep
		 neural networks in the 13th Critical Assessment of
		 Protein Structure Prediction (CASP13)},
  journal  = {WileyOnlineLibrary},
  month    = oct,
  year     = {2019},
  keywords = {jrnl, MolBio, CASP, CASP13, c2019, c201x, c20xx,
		 zz1219, AlphaFold, A7D, DeepMind, protein structure
		 prediction, pairwise distance, Zscores, GDT\_TS, GDTTS,
		 GDTnet, google},
  abstract = {{"}We describe AlphaFold, the protein structure
		 prediction system that was entered by the group A7D in
		 CASP13. Submissions were made by three free-modeling
		 (FM) methods which combine the predictions of three
		 neural networks. All three systems were guided by
		 predictions of distances between pairs of residues
		 produced by a NN. Two systems assembled fragments
		 produced by a generative NN, one using scores from a
		 n/wk trained to regress GDT\_TS. The third system shows
		 that simple gradient descent on a properly constructed
		 potential is able to perform on par with more expensive
		 traditional search techniques \& without requiring
		 domain segmentation. In the CASP13 FM assessors'
		 ranking by summed z-scores, this system scored highest
		 with 68.3 vs 48.2 for the next closest group (an
		 average GDT\_TS of 61.4). The system produced
		 high-accuracy structures (with GDT\_TS scores of 70 or
		 higher) for 11 out of 43 FM domains. Despite not
		 explicitly using template information, the results in
		 the template category were comparable to the best
		 performing template-based methods.{"} [36 refs.] --
		 [https://doi.org/10.1002/prot.25834
		 (doi:10.1002/prot.25834)]['19]. (*Also see
		 alphafold@[https://deepmind.com/blog/article/alphafold
		 (deepmind)]['19].*) [Also search for: MolBio
		 alphafold].}
}

@inproceedings{neuralnetworksgames:michulke,
  title     = {Neural Networks for State Evaluation in General Game
		 Playing},
  author    = {Daniel Michulke and Michael Thielscher},
  bibdate   = {2018-06-26},
  bibsource = {DBLP,
		 http://dblp.uni-trier.de/https://doi.org/10.1007/978-3-642-04174-7_7;
		 DBLP,
		 http://dblp.uni-trier.de/db/conf/pkdd/pkdd2009-2.html#MichulkeT09},
  booktitle = {Machine Learning and Knowledge Discovery in Databases,
		 European Conference, ECML PKDD 2009, Bled, Slovenia,
		 September 7-11, 2009, Proceedings, Part II},
  publisher = {Springer},
  year      = {2009},
  volume    = {5782},
  booktitle = {ECML/PKDD (2)},
  editor    = {Wray L. Buntine and Marko Grobelnik and Dunja Mladenic
		 and John Shawe-Taylor},
  isbn      = {978-3-642-04173-0},
  pages     = {95--110},
  series    = {Lecture Notes in Computer Science}
}

@inproceedings{mcts:coulom,
  title     = {Efficient Selectivity and Backup Operators in
		 Monte-Carlo Tree Search},
  author    = {Rémi Coulom},
  publisher = {Springer},
  year      = {2006},
  volume    = {4630},
  bibdate   = {2017-05-17},
  bibsource = {DBLP,
		 http://dblp.uni-trier.de/https://doi.org/10.1007/978-3-540-75538-8_7;
		 DBLP,
		 http://dblp.uni-trier.de/db/conf/cg/cg2006.html#Coulom06},
  booktitle = {Computers and Games},
  editor    = {H. Jaap van den Herik and Paolo Ciancarini and H. H. L. M. Donkers},
  isbn      = {978-3-540-75537-1},
  pages     = {72--83},
  series    = {Lecture Notes in Computer Science}
}
@techreport{abpruning:dj,
  author      = {T. P. Hart and D. J. Edwards},
  title       = {The Alpha-Beta Heuristic},
  institution = {Massachusettes Institute of Technology},
  year        = {1963},
  number      = {30},
  address     = {Cambridge, MA},
  month       = oct,
  avcode      = {$^*$}
}

@article{legalexplanation:goodman,
  title     = {European Union Regulations on Algorithmic
		 Decision-Making and a Right to Explanation},
  author    = {Bryce Goodman and Seth R. Flaxman},
  journal   = {AI Magazine},
  year      = {2017},
  number    = {3},
  volume    = {38},
  bibdate   = {2020-08-13},
  bibsource = {DBLP,
		 http://dblp.uni-trier.de/https://doi.org/10.1609/aimag.v38i3.2741;
		 DBLP,
		 http://dblp.uni-trier.de/https://www.wikidata.org/entity/Q64191227;
		 DBLP,
		 http://dblp.uni-trier.de/db/journals/aim/aim38.html#GoodmanF17},
  pages     = {50--57}
}

@phdthesis{qlearning:watkins,
  author = {{C. J. C. H. Watkins}},
  title  = {Learning from Delayed Rewards},
  school = {King's College},
  year   = {1989}
}

@misc{siggi:github,
  author       = {Sigurður Helgason},
  title        = {TCav-{B}reakthrough},
  year         = {2020},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{https://github.com/sigurdurhelga/msc-chess}}
}

@article{ling:dbscan,
  title     = {On the theory and construction of k -clusters},
  author    = {Robert F. Ling},
  journal   = {Comput. J},
  year      = {1972},
  number    = {4},
  volume    = {15},
  bibdate   = {2018-11-14},
  bibsource = {DBLP,
		 http://dblp.uni-trier.de/https://doi.org/10.1093/comjnl/15.4.326;
		 DBLP,
		 http://dblp.uni-trier.de/https://www.wikidata.org/entity/Q57253968;
		 DBLP,
		 http://dblp.uni-trier.de/db/journals/cj/cj15.html#Ling72},
  pages     = {326--332}
}

@article{lloyd:kmeans,
  author  = {S. P. Lloyd},
  title   = {Least squares quantization in {PCM}\@},
  journal = {IEEE Transactions on Information Theory},
  volume  = {28},
  pages   = {128--137},
  year    = {1982},
  comment = {Reference from PRNN}
}

@misc{kocsis:uct,
  title     = {Bandit based monte-carlo planning},
  author    = {L Kocsis and Csaba Szepesvari},
  year      = {2006},
  month     = sep,
  abstract  = {For large state-space Markovian Decision Problems
		 Monte-Carlo planning is one of the few viable
		 approaches to find near-optimal solutions. In this
		 paper we introduce a new algorithm, UCT, that applies
		 bandit ideas to guide Monte-Carlo planning. In
		 finite-horizon or discounted MDPs the algorithm is
		 shown to be consistent and finite sample bounds are
		 derived on the estimation error due to sampling.
		 Experimental results show that in several domains, UCT
		 is significantly more efficient than its
		 alternatives.},
  bibsource = {OAI-PMH server at eprints.pascal-network.org},
  oai       = {oai:eprints.pascal-network.org:6352},
  subject   = {Computational, Information-Theoretic Learning with
		 Statistics; Learning/Statistics \& Optimisation; Theory
		 \& Algorithms},
  type      = {Conference or Workshop Item; PeerReviewed},
  url       = {http://eprints.pascal-network.org/archive/00006352/;
		 http://www.sztaki.hu/~szcsaba/papers/ecml06.pdf}
}

@article{rosin:puct,
  title     = {Multi-armed bandits with episode context},
  author    = {Christopher D. Rosin},
  journal   = {Ann. Math. Artif. Intell},
  year      = {2011},
  number    = {3},
  volume    = {61},
  bibdate   = {2017-05-28},
  bibsource = {DBLP,
		 http://dblp.uni-trier.de/https://doi.org/10.1007/s10472-011-9258-6;
		 DBLP,
		 http://dblp.uni-trier.de/db/journals/amai/amai61.html#Rosin11},
  pages     = {203--230}
}

@article{karras:stylegan,
  title     = {A Style-Based Generator Architecture for Generative
		 Adversarial Networks},
  author    = {Tero Karras and Samuli Laine and Timo Aila},
  journal   = {CoRR},
  year      = {2018},
  volume    = {abs/1812.04948},
  bibdate   = {2019-01-01},
  bibsource = {DBLP,
		 http://dblp.uni-trier.de/db/journals/corr/corr1812.html#abs-1812-04948},
  url       = {http://arxiv.org/abs/1812.04948}
}

@article{rumelhard:backprop,
  author  = {D. Rumelhart and G. Hinton and R. Williams},
  title   = {Learning representations by back-propagating errors},
  journal = {Nature},
  volume  = {323},
  month   = oct,
  year    = {1986},
  pages   = {533--536}
}

@article{Silver:alphazero,
  author   = {D. Silver and et al ... and D. Hassabis},
  title    = {Mastering chess and shogi by self-play with a general
		 reinforcement learning algorithm},
  journal  = {arXiv},
  month    = dec,
  year     = {2017},
  keywords = {TR, c2017, c201x, c20xx, zz1217, Chess, Shogi, game,
		 playing, program, AI, deep learning, reinforcement
		 learning, AlphaGo Zero, AlphaZero, ANN},
  abstract = {{"}... we generalise [AlphaGo Zero's] approach into a
		 single AlphaZero alg. that can achieve, tabula rasa,
		 superhuman performance in many challenging domains.
		 Starting from random play, \& given no domain knowledge
		 except the game rules, AlphaZero achieved within 24
		 hours a superhuman level of play in the games of chess
		 \& shogi (Japanese chess) as well as Go, \&
		 convincingly defeated a world-champion program in each
		 case.{"} --
		 1712.01815@[https://arxiv.org/abs/1712.01815
		 (arXiv)]['17].}
}

@article{brown:retinopathy,
  title      = {Automated diagnosis of plus disease in retinopathy of
		 prematurity using deep convolutional neural networks},
  author     = {James Brown and J Peter Campbell and Andrew Beers and
		 Ken Chang and Susan Ostmo and RV Paul Chan and Jennifer
		 Dy and Deniz Erdogmus and Stratis Ioannidis and
		 Jayashree Kalpathy-Cramer and Michael F Chiang},
  publisher  = {American Medical Association},
  year       = {2018},
  month      = jul,
  abstract   = {Importance: Retinopathy of prematurity (ROP) is a
		 leading cause of childhood blindness worldwide. The
		 decision to treat is primarily based on the presence of
		 plus disease, defined as dilation and tortuosity of
		 retinal vessels. However, clinical diagnosis of plus
		 disease is highly subjective and variable. Objective:
		 To implement and validate an algorithm based on deep
		 learning to automatically diagnose plus disease from
		 retinal photographs. Design, Setting, and Participants:
		 A deep convolutional neural network was trained using a
		 data set of 5511 retinal photographs. Each image was
		 previously assigned a reference standard diagnosis
		 (RSD) based on consensus of image grading by 3 experts
		 and clinical diagnosis by 1 expert (ie, normal,
		 pre--plus disease, or plus disease). The algorithm was
		 evaluated by 5-fold cross-validation and tested on an
		 independent set of 100 images. Images were collected
		 from 8 academic institutions participating in the
		 Imaging and Informatics in ROP (i-ROP) cohort study.
		 The deep learning algorithm was tested against 8 ROP
		 experts, each of whom had more than 10 years of
		 clinical experience and more than 5 peer-reviewed
		 publications about ROP. Data were collected from July
		 2011 to December 2016. Data were analyzed from December
		 2016 to September 2017. Exposures: A deep learning
		 algorithm trained on retinal photographs. Main Outcomes
		 and Measures: Receiver operating characteristic
		 analysis was performed to evaluate performance of the
		 algorithm against the RSD. Quadratic-weighted
		 {$\kappa$} coefficients were calculated for ternary
		 classification (ie, normal, pre--plus disease, and plus
		 disease) to measure agreement with the RSD and 8
		 independent experts. Results: Of the 5511 included
		 retinal photographs, 4535 (82.3\%) were graded as
		 normal, 805 (14.6\%) as pre--plus disease, and 172
		 (3.1\%) as plus disease, based on the RSD. Mean (SD)
		 area under the receiver operating characteristic curve
		 statistics were 0.94 (0.01) for the diagnosis of normal
		 (vs pre--plus disease or plus disease) and 0.98 (0.01)
		 for the diagnosis of plus disease (vs normal or
		 pre--plus disease). For diagnosis of plus disease in an
		 independent test set of 100 retinal images, the
		 algorithm achieved a sensitivity of 93\% with 94\%
		 specificity. For detection of pre--plus disease or
		 worse, the sensitivity and specificity were 100\% and
		 94\%, respectively. On the same test set, the algorithm
		 achieved a quadratic-weighted {$\kappa$} coefficient of
		 0.92 compared with the RSD, outperforming 6 of 8 ROP
		 experts. Conclusions and Relevance: This fully
		 automated algorithm diagnosed plus disease in ROP with
		 comparable or better accuracy than human experts. This
		 has potential applications in disease detection,
		 monitoring, and prognosis in infants at risk of ROP.},
  issn       = {2168-6165},
  bibsource  = {OAI-PMH server at eprints.lincoln.ac.uk},
  identifier = {Brown, James and Campbell, J Peter and Beers, Andrew
		 and Chang, Ken and Ostmo, Susan and Chan, RV Paul and
		 Dy, Jennifer and Erdogmus, Deniz and Ioannidis, Stratis
		 and Kalpathy-Cramer, Jayashree and Chiang, Michael F
		 (2018) Automated diagnosis of plus disease in
		 retinopathy of prematurity using deep convolutional
		 neural networks. JAMA Ophthalmology, 136 (7). pp.
		 803-810. ISSN 2168-6165},
  oai        = {oai:eprints.lincoln.ac.uk:35638},
  pages      = {803--810},
  relation   = {10.1001/jamaophthalmol.2018.1934},
  subject    = {G740 Computer Vision; G760 Machine Learning; G400
		 Computer Science; B800 Medical Technology},
  type       = {PeerReviewed},
  url        = {http://eprints.lincoln.ac.uk/35638/;
		 http://doi.org/10.1001/jamaophthalmol.2018.1934}
}

@misc{simonyan:imagerecognition,
  title     = {Very Deep Convolutional Networks for Large-Scale Image
		 Recognition},
  author    = {Karen Simonyan and Andrew Zisserman},
  year      = {2014},
  month     = apr # {~10},
  abstract  = {In this work we investigate the effect of the
		 convolutional network depth on its accuracy in the
		 large-scale image recognition setting. Our main
		 contribution is a thorough evaluation of networks of
		 increasing depth using an architecture with very small
		 (3x3) convolution filters, which shows that a
		 significant improvement on the prior-art configurations
		 can be achieved by pushing the depth to 16-19 weight
		 layers. These findings were the basis of our ImageNet
		 Challenge 2014 submission, where our team secured the
		 first and the second places in the localisation and
		 classification tracks respectively. We also show that
		 our representations generalise well to other datasets,
		 where they achieve state-of-the-art results. We have
		 made our two best-performing ConvNet models publicly
		 available to facilitate further research on the use of
		 deep visual representations in computer vision.},
  bibsource = {OAI-PMH server at export.arxiv.org},
  oai       = {oai:arXiv.org:1409.1556},
  subject   = {Computer Science - Computer Vision and Pattern
		 Recognition},
  url       = {http://arxiv.org/abs/1409.1556}
}

@article{kourou:cancer,
  title     = {Machine learning applications in cancer prognosis and
		 prediction},
  author    = {Konstantina Kourou and Themis P. Exarchos and
		 Konstantinos P. Exarchos and Michalis V. Karamouzis and
		 Dimitrios I. Fotiadis},
  publisher = {Research Network of Computational and Structural
		 Biotechnology},
  year      = {2014},
  month     = nov # {~15},
  abstract  = {Cancer has been characterized as a heterogeneous
		 disease consisting of many different subtypes. The
		 early diagnosis and prognosis of a cancer type have
		 become a necessity in cancer research, as it can
		 facilitate the subsequent clinical management of
		 patients. The importance of classifying cancer patients
		 into high or low risk groups has led many research
		 teams, from the biomedical and the bioinformatics
		 field, to study the application of machine learning
		 (ML) methods. Therefore, these techniques have been
		 utilized as an aim to model the progression and
		 treatment of cancerous conditions. In addition, the
		 ability of ML tools to detect key features from complex
		 datasets reveals their importance. A variety of these
		 techniques, including Artificial Neural Networks
		 (ANNs), Bayesian Networks (BNs), Support Vector
		 Machines (SVMs) and Decision Trees (DTs) have been
		 widely applied in cancer research for the development
		 of predictive models, resulting in effective and
		 accurate decision making. Even though it is evident
		 that the use of ML methods can improve our
		 understanding of cancer progression, an appropriate
		 level of validation is needed in order for these
		 methods to be considered in the everyday clinical
		 practice. In this work, we present a review of recent
		 ML approaches employed in the modeling of cancer
		 progression. The predictive models discussed here are
		 based on various supervised ML techniques as well as on
		 different input features and data samples. Given the
		 growing trend on the application of ML methods in
		 cancer research, we present here the most recent
		 publications that employ these techniques as an aim to
		 model cancer risk or patient outcomes.},
  bibsource = {OAI-PMH server at www.ncbi.nlm.nih.gov},
  language  = {en},
  oai       = {oai:pubmedcentral.nih.gov:4348437},
  rights    = {{\copyright} 2014 Kourou et al. Published by Elsevier
		 B.V. on behalf of the Research Network of Computational
		 and Structural Biotechnology.;
		 http://creativecommons.org/licenses/by/3.0/; This is an
		 open access article under the CC BY license
		 (http://creativecommons.org/licenses/by/3.0/).},
  subject   = {Mini Review},
  url       = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC;
		 http://www.ncbi.nlm.nih.gov/pubmed/25750696;
		 http://dx.doi.org/10.1016/j.csbj.2014.11.005}
}

@article{riberio:recentxai1,
  title     = {Model-Agnostic Interpretability of Machine Learning},
  author    = {Marco T{\'u}lio Ribeiro and Sameer Singh 0001 and
		 Carlos Guestrin},
  journal   = {CoRR},
  year      = {2016},
  volume    = {abs/1606.05386},
  bibdate   = {2018-08-13},
  bibsource = {DBLP,
		 http://dblp.uni-trier.de/db/journals/corr/corr1606.html#RibeiroSG16a},
  url       = {http://arxiv.org/abs/1606.05386}
}

@article{sutton:tdlambda,
  author  = {R. S. Sutton},
  title   = {Learning to Predict by the Methods of Temporal
		 Differences},
  journal = {Machine Learning},
  year    = {1988},
  volume  = {3},
  pages   = {9--44}
}

@article{tjoa:surveyxai,
  title     = {A Survey on Explainable Artificial Intelligence (XAI):
		 Towards Medical XAI},
  author    = {Erico Tjoa and Cuntai Guan},
  journal   = {CoRR},
  year      = {2019},
  volume    = {abs/1907.07374},
  bibdate   = {2019-07-23},
  bibsource = {DBLP,
		 http://dblp.uni-trier.de/db/journals/corr/corr1907.html#abs-1907-07374},
  url       = {http://arxiv.org/abs/1907.07374}
}

@inproceedings{hinton:relu,
  title     = {Rectified Linear Units Improve Restricted Boltzmann
		 Machines},
  author    = {Vinod Nair and Geoffrey E. Hinton},
  bibdate   = {2019-04-03},
  bibsource = {DBLP,
		 http://dblp.uni-trier.de/https://icml.cc/Conferences/2010/papers/432.pdf;
		 DBLP,
		 http://dblp.uni-trier.de/db/conf/icml/icml2010.html#NairH10},
  booktitle = {Proceedings of the 27th International Conference on
		 Machine Learning (ICML-10), June 21-24, 2010, Haifa,
		 Israel},
  publisher = {Omnipress},
  year      = {2010},
  booktitle = {ICML},
  editor    = {Johannes F{\"u}rnkranz and Thorsten Joachims},
  pages     = {807--814}
}