\chapter{Discussion}

This section discusses the results and the future work that could span from this research. Additionally, we conclude the work.

\section{Summary}

As seen in Chapter \ref{cha:results}, our trained agent does indeed quickly rise to using the higher-level concepts. The results are promising, as we see a popular concepts like Lorentz-Horey rise in emphasis for the neural network, and a simple but effective concept like Material Advantage rise slowly but not exessively. We find the Unity concept to be disappointing as stated earlier in this paper maintaining closeness of your pawns tends to be preferential. And lastly, for a the concept Aggressiveness, the fact that it falls off early is what we expected. It would have been the preferred result if we saw a greater variability in the concepts, but this could be a result from not enough training iterations, or not a complex enough model. Importantly, these concepts are only a few possibilities of an infinite set of concepts, and the neural network could be learning a completely different concept then those that we tested. However, that was not the focus of this research, it was to examine if a neural network does move towards HLC's that we humans use in games.

\section{Future Work}

To iterate on this research, training a neural network with greater computing power will allow the researchers to hopefully achieve a super-human neural network in Breakthrough. This would give a greater confidence in the learned concepts, possibly allowing for pedagological research on the topic regarding which concepts are optimal to train people in the game environment. This could also arise from a larger neural network architecture.

An avenue of research would be to use a trained AlphaZero model that plays chess to a super human ability, and be able to draw from a more diverse set of concepts. Furthermore, one could examine the play-style of the super-human model to extract concepts in order to construct new and improved heuristics for a non-neural network based agent.

Additionally applying this method to a greater set of environment would be an interesting field of research. We envision a self driving car agent being examined with respect to a higher level concept of aggressiveness, or a mortgage agent being examined with respect to a higher level concept of gender bias.

\section{Conclusion}

The work done in this paper is only a first step in examining working agents in active environments with respect to human level concepts. If improved could have a great impact in our trust on neural network that improve our daily lives. While the testbed for the research was a discrete game environment, there is a clear way forward to a dynamic system with discrete human level concepts. Our results show that for an agent that clearly doesn't achieve human level performance it's actions are often selected with respect to human level concepts, up to 60\% of the actions.
