\chapter{Discussion}

This chapter discusses the results and the future work that could span from this research. Additionally, we conclude the work.

\section{Summary}

As seen in Chapter \ref{cha:results}, our trained agent does indeed quickly rise to using the higher-level concepts, thus answering our research question \ref{rq:1}. The results are promising, as we see a popular concepts like Lorentz-Horey score rise in emphasis for the neural network, and a simple but effective concept like Material Advantage rise slowly but not exessively. We find the Unity concept to be disappointing as stated earlier in this paper; maintaining closeness of your pawns tends to be preferential. And lastly, for a the concept Aggressiveness, the fact that it falls off early is what we expected. It would have been the preferred result if we saw a greater variability in the concepts, but this could be a result from not enough training iterations, or not a complex enough model. Considering that the most emphazised HLC is the Lorentz-Horey score, and that the least is Unity, we can answer our research question \ref{rq:2}. As we know from the literature, Lorentz-Horey is considered the leading heuristic for Breakthrough, and that HLC is highly emphazised by the neural network. Secondly, the Unity heuristic is not a validated heuristic, moreso, an attempt at creating a simple heuristic that closely resembles how tight-packed your pawns are. However, the fact that the resulting graphs are relatively steady the results are not as strong as we would have hoped. 

Importantly, these concepts are only a few possibilities of an infinite set of concepts, and the neural network could be learning a completely different concept then those that we tested. However, that was not the focus of this research, it was to examine if a neural network does move towards HLC's that we humans use in games.

\section{Future Work}

To iterate on this research, training a neural network with greater computing power, or with a larger neural network architecture, will allow the us to hopefully achieve a super-human neural network in Breakthrough. This would give greater confidence in the learned concepts, possibly allowing for pedagogical research on the topic regarding which concepts are optimal to train people in the game environment.

The work done in this thesis was only a proof of concept of the process of explaining the internal concept a neural network uses while acting in a board game environment. Ideally, one would like to extend this work to a larger set of board games.

Additionally applying this method to a more diverse set of environments would be an interesting field of research. We envision a self driving car agent being examined with respect to a higher level concept of aggressiveness, or a mortgage agent being examined with respect to a higher level concept of gender bias.

\section{Conclusion}

The work done in this paper is only a first step in examining working agents in active environments with respect to human level concepts. If improved it could have a great impact in our trust on neural network that improve our daily lives. While the testbed for the research was a discrete game environment, there is a clear way forward to dynamic systems with discrete human level concepts. Our results show that for an agent that clearly doesn't achieve human level performance its actions are often selected with respect to human level concepts.
